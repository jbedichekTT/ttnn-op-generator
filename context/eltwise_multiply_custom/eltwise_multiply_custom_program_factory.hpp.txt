Required APIs (8):
  - tt::tt_metal::operation::ProgramWithCallbacks

  - tt::tt_metal::Program

  - tt::tt_metal::CreateKernel

  - tt::tt_metal::CoreRangeSet
    ✓ Validated in: ttnn/api/ttnn/types.hpp

  - ttnn::Tensor
    ✓ Validated in: ttnn/api/ttnn/tensor/tensor.hpp


Required Includes (6):
  - <tt-metalium/host_api.hpp>
    Reason: Core TT-Metal APIs for Program, kernels, and circular buffers
    Expected: Program, CreateReadKernel, CreateWriteKernel, CreateComputeKernel, CreateCircularBuffer
  - ttnn/tensor/tensor.hpp
    Reason: Tensor type definition and utilities
    Expected: Tensor
  - tt_metal/impl/dispatch/command_queue.hpp
    Reason: Program execution and dispatch
    Expected: ProgramWithCallbacks
  - ttnn/operation.hpp
    Reason: Operation framework types
    Expected: operation::ProgramWithCallbacks
  - ttnn/api/ttnn/types.hpp
    Reason: Required for CoreRangeSet
    Expected: CoreRangeSet
  - ttnn/api/ttnn/tensor/tensor.hpp
    Reason: Required for Tensor
    Expected: Tensor

Namespace Imports:
  - using namespace tt::tt_metal;
  - using namespace tt::tt_metal::operation;
  - using namespace ttnn;

Key Patterns to Follow:
  - Function should return tt::tt_metal::operation::ProgramWithCallbacks
  - Use CreateReadKernel for eltwise_multiply_custom_reader.cpp
  - Use CreateWriteKernel for eltwise_multiply_custom_writer.cpp
  - Use CreateComputeKernel for eltwise_multiply_custom_compute.cpp
  - Create circular buffers for input A, input B, and output tensors
  - Configure kernels with appropriate core ranges and runtime arguments
  - Kernel file paths should be relative to kernels/ directory
  - Use proper data format specifications for circular buffers
  - Handle both single-core and multi-core execution strategies

Common Mistakes to Avoid:
  - Don't hardcode core coordinates - use flexible core range specification
  - Don't forget to configure circular buffer sizes appropriately for tensor dimensions
  - Don't mix up reader/writer kernel file names - must match the generated kernel files
  - Include proper compile-time and runtime argument passing to kernels
  - Don't forget to handle tensor memory layout and data format requirements
  - Include proper error handling for invalid tensor shapes or device constraints


================================================================================
FINAL GENERATION PROMPT
================================================================================

Generate the code for the file `device/eltwise_multiply_custom_program_factory.hpp` for the `eltwise_multiply_custom` operation.


        # TT-Metal Program Factory Development Context

        ## Program Factory Role & Responsibilities

        ### Core Purpose
        Program factories are **orchestration engines** that:
        - **Create and configure programs** that coordinate multiple kernels
        - **Manage memory layouts** and circular buffer configurations
        - **Dispatch work** across single or multiple cores
        - **Handle runtime arguments** and tensor shape adaptations
        - **Optimize execution** based on tensor properties and hardware constraints

        IMPORTANT: The kernels called in the program factory must be the readers and writers generated, not any existing kernels.
        This means the correct kernels are named `{operation_name}_reader.cpp`, `<operation_name>_writer.cpp`, and `<operation_name>_compute.cpp`.
        **Include Path Context for TTNN Operations:**
    The CMake build system provides include paths at these levels:
    - `{repo_root}/ttnn/`
    - `{repo_root}/ttnn/cpp/`

    Therefore, #include statements must be relative to these paths:

    Here is the structure for the file system you are generating:
    ttnn/cpp/ttnn/operations/{operation_name}/
    ├── CMakeLists.txt              # CMake
    ├── {operation_name}.hpp        # Main header
    ├── {operation_name}.cpp        # Main implementation
    ├── {operation_name}_pybind.hpp # Pybind header
    ├── {operation_name}_pybind.cpp # Pybind implementation
    └── device/                     # Device-specific code
        ├── {operation_name}_op.hpp
        ├── {operation_name}_op.cpp
        ├── {operation_name}_program_factory.hpp
        ├── {operation_name}_program_factory.cpp
        └── kernels/
            ├── compute/
            │   └── {operation_name}_compute.cpp
            └── dataflow/
                ├── {operation_name}_reader.cpp
                └── {operation_name}_writer.cpp
    
    
    Quick Tool Usage Guide:

    find_api_usages
    When to use: Need to understand how a function/API is used in the codebase

    Finding correct parameters for a function call
    Understanding usage patterns and best practices
    Resolving "no matching function" errors by seeing working examples

    Example triggers: "How is X used?", "Show me examples of Y", "What parameters does Z take?"
    
    parse_and_analyze_code
    When to use: Need to understand the structure of a C++ file

    Before making edits (to understand what's already there)
    Finding functions, classes, includes, namespaces in a file
    Checking if certain elements exist before adding them
    Understanding file organization and dependencies

    Example triggers: "What's in this file?", "Does this file have X?", "Analyze the structure"
    
    apply_targeted_edits
    When to use: Need to modify C++ code programmatically which has already been generated (i.e not during initial generation)

    Adding missing includes
    Inserting new functions or classes
    Modifying existing code elements
    Deleting problematic code
    Making precise edits while preserving file structure

    Example triggers: "Add include for X", "Insert function Y", "Fix the implementation", "Remove Z"


        VALIDATED API INFORMATION:
        - tt::tt_metal::CoreRangeSet
  Include: ttnn/api/ttnn/types.hpp
  Purpose: specify which cores to run kernels on

- ttnn::Tensor
  Include: ttnn/api/ttnn/tensor/tensor.hpp
  Purpose: input and output tensor types


        REQUIRED HEADERS:
        #include "tt_metal/host_api.hpp"
  // Core TT-Metal APIs for Program, kernels, and circular buffers
#include "ttnn/tensor/tensor.hpp"
  // Tensor type definition and utilities
  // Provides: 1 classes, 1 constants, 23 functions, 4 namespaces, 4 template_functions
#include "tt_metal/impl/dispatch/command_queue.hpp"
  // Program execution and dispatch
#include "ttnn/operation.hpp"
  // Operation framework types
  // Provides: 2 classes, 1 constants, 4 namespaces, 6 structs
#include "ttnn/api/ttnn/types.hpp"
  // Required for CoreRangeSet
#include "ttnn/api/ttnn/tensor/tensor.hpp"
  // Required for Tensor

        NAMESPACE USAGE:
        tt::tt_metal, tt::tt_metal::operation, ttnn
        
Key Implementation Patterns:
- Function should return tt::tt_metal::operation::ProgramWithCallbacks
- Use CreateReadKernel for eltwise_multiply_custom_reader.cpp
- Use CreateWriteKernel for eltwise_multiply_custom_writer.cpp
- Use CreateComputeKernel for eltwise_multiply_custom_compute.cpp
- Create circular buffers for input A, input B, and output tensors
- Configure kernels with appropriate core ranges and runtime arguments
- Kernel file paths should be relative to kernels/ directory
- Use proper data format specifications for circular buffers
- Handle both single-core and multi-core execution strategies
        
Common Mistakes to Avoid:
- Don't hardcode core coordinates - use flexible core range specification
- Don't forget to configure circular buffer sizes appropriately for tensor dimensions
- Don't mix up reader/writer kernel file names - must match the generated kernel files
- Include proper compile-time and runtime argument passing to kernels
- Don't forget to handle tensor memory layout and data format requirements
- Include proper error handling for invalid tensor shapes or device constraints

Generate the complete implementation for device/eltwise_multiply_custom_program_factory.hpp.
Use only the validated APIs and includes in the header file, do not add any new ones.